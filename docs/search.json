[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I aim to teach R and Python programming languages with hands-on examples."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Uraz's R and Python Blog",
    "section": "",
    "text": "Finance\n\n\nEnglish\n\n\n\n\nBuild your best portfolio.\n\n\n\n\n\n\nNov 28, 2022\n\n\nUraz Akgül\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nFinance\n\n\nEnglish\n\n\n\n\nDetermine the best and worst days for returns for BIST100.\n\n\n\n\n\n\nNov 2, 2022\n\n\nUraz Akgül\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20221102_post1/index.html",
    "href": "posts/20221102_post1/index.html",
    "title": "What Are the Best and Worst Days of the Week for Returns?",
    "section": "",
    "text": "The data you can access by downloading the post1.xlsx file from here is from Reuters.\n\nR\n\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(scales)\nlibrary(ggrepel)\n\n\nbist100 <- read_excel(\"data.xlsx\")\nbist100$DATE <- ymd(bist100$DATE)\n\n#head(bist100)\n\n\n\n\n\n\nDATE\nCLOSE\n\n\n\n\n2002-12-31\n103.6992\n\n\n2003-01-02\n105.9858\n\n\n2003-01-03\n108.3753\n\n\n2003-01-06\n103.5734\n\n\n2003-01-07\n97.5286\n\n\n2003-01-08\n101.6121\n\n\n\n\n\nHow to calculate rates of return:\n\nbist100 <- bist100 %>%\nmutate(\n    DAY = weekdays(DATE)\n)\n\n#head(bist100)\n\n\n\n\n\n\nDATE\nCLOSE\nDAY\n\n\n\n\n2002-12-31\n103.6992\nTuesday\n\n\n2003-01-02\n105.9858\nThursday\n\n\n2003-01-03\n108.3753\nFriday\n\n\n2003-01-06\n103.5734\nMonday\n\n\n2003-01-07\n97.5286\nTuesday\n\n\n2003-01-08\n101.6121\nWednesday\n\n\n\n\n\n\\[\nr_i = \\frac{P_{t+1}-P_t}{P_t} = \\frac{P_{t+1}}{P_t} - 1\n\\]\n\\[\nr_i = Return\\ on\\ a\\ stock\\ i\n\\]\n\\[\nP_t = Price\\ of\\ the\\ stock\\ at\\ time\\ t\n\\]\n\\[\nP_{t+1} = Price\\ of\\ the\\ stock\\ at\\ time\\ t+1\n\\]\n\nbist100 <- bist100 %>%\nmutate(\n    RETURN = lag(lead(CLOSE) / CLOSE - 1)\n) %>%\nna.omit()\n\n#head(bist100)\n\n\n\n\n\n\nDATE\nCLOSE\nDAY\nRETURN\n\n\n\n\n2003-01-02\n105.9858\nThursday\n0.0220503\n\n\n2003-01-03\n108.3753\nFriday\n0.0225455\n\n\n2003-01-06\n103.5734\nMonday\n-0.0443081\n\n\n2003-01-07\n97.5286\nTuesday\n-0.0583625\n\n\n2003-01-08\n101.6121\nWednesday\n0.0418698\n\n\n2003-01-09\n102.2582\nThursday\n0.0063585\n\n\n\n\n\nThe mean and standard deviation of returns based on weekdays:\n\nresult <- bist100 %>%\ngroup_by(DAY) %>%\nsummarise(\n    r_mean = mean(RETURN),\n    r_sd = sd(RETURN)\n) %>%\nungroup() %>%\nmutate(\n    DAY = factor(\n        DAY,\n        levels = c(\n            \"Monday\",\n            \"Tuesday\",\n            \"Wednesday\",\n            \"Thursday\",\n            \"Friday\"\n        )\n    )\n) %>%\narrange(DAY)\n\n#result\n\n\n\n\n\n\nDAY\nr_mean\nr_sd\n\n\n\n\nMonday\n0.0010109\n0.0198846\n\n\nTuesday\n0.0008139\n0.0164530\n\n\nWednesday\n0.0005155\n0.0155066\n\n\nThursday\n0.0009036\n0.0173621\n\n\nFriday\n0.0011200\n0.0152668\n\n\n\n\n\nBarplot (Average Returns):\n\nggplot(result, aes(x = DAY, y = r_mean, fill = r_mean)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = .5, size = 10)\n) +\nscale_fill_gradient(low = \"orange\", high = \"red\") +\nscale_y_continuous(labels = comma) +\nlabs(\n    title = \"What Are the Best and Worst Days of the Week for Returns for BIST100?\"\n)\n\n\n\n\nScatterplot (Average Returns vs Standard Deviations):\n\nggplot(result, aes(x = r_mean, y = r_sd)) +\ngeom_point(size = 5, alpha = .5) +\ngeom_text_repel(aes(label = DAY)) +\ntheme_fivethirtyeight() +\ntheme(\n    axis.title = element_text()\n) +\nscale_y_continuous(labels = comma) +\nscale_x_continuous(labels = comma) +\nlabs(\n    x = \"Average\",\n    y = \"Standard Deviation\"\n)\n\n\n\n\n\n\nPython\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n\n\nbist100 = pd.read_excel(\"data.xlsx\")\nbist100.head()\n\n        DATE     CLOSE\n0 2002-12-31  103.6992\n1 2003-01-02  105.9858\n2 2003-01-03  108.3753\n3 2003-01-06  103.5734\n4 2003-01-07   97.5286\n\n\nHow to calculate rates of return:\n\n\nbist100['DAY'] = bist100['DATE'].dt.day_name()\nbist100.head()\n\n        DATE     CLOSE       DAY\n0 2002-12-31  103.6992   Tuesday\n1 2003-01-02  105.9858  Thursday\n2 2003-01-03  108.3753    Friday\n3 2003-01-06  103.5734    Monday\n4 2003-01-07   97.5286   Tuesday\n\n\n\\[\nr_i = \\frac{P_{t+1}-P_t}{P_t} = \\frac{P_{t+1}}{P_t} - 1\n\\]\n\\[\nr_i = Return\\ on\\ a\\ stock\\ i\n\\]\n\\[\nP_t = Price\\ of\\ the\\ stock\\ at\\ time\\ t\n\\]\n\\[\nP_{t+1} = Price\\ of\\ the\\ stock\\ at\\ time\\ t+1\n\\]\n\n\nbist100['RETURN'] = bist100['CLOSE'].pct_change()\nbist100 = bist100.dropna()\nbist100.head()\n\n        DATE     CLOSE        DAY    RETURN\n1 2003-01-02  105.9858   Thursday  0.022050\n2 2003-01-03  108.3753     Friday  0.022545\n3 2003-01-06  103.5734     Monday -0.044308\n4 2003-01-07   97.5286    Tuesday -0.058362\n5 2003-01-08  101.6121  Wednesday  0.041870\n\n\nThe mean and standard deviation of returns based on weekdays:\n\n\nr_mean = bist100.groupby('DAY')['RETURN'].mean()\nr_std = bist100.groupby('DAY')['RETURN'].std()\n\nresult = pd.DataFrame()\nresult['r_mean'] = r_mean\nresult['r_std'] = r_std\n\nresult.reset_index(inplace = True)\n\nresult['DAY'] = result['DAY'].astype(\"category\")\n\nday_list = [\n    'Monday',\n    'Tuesday',\n    'Wednesday',\n    'Thursday',\n    'Friday'\n]\n\nresult['DAY'] = result['DAY'].cat.reorder_categories(day_list)\n\nresult['DAY']\n\n0       Friday\n1       Monday\n2     Thursday\n3      Tuesday\n4    Wednesday\nName: DAY, dtype: category\nCategories (5, object): ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n\n\nBarplot (Average Returns):\n\n\nfig = plt.figure(figsize = (10, 7))\nbplt = sns.barplot(\n    x = 'DAY',\n    y = 'r_mean',\n    data = result,\n    palette = 'rocket'\n)\nbplt.set_title(\n    label = 'What Are the Best and Worst Days of the Week for Returns for BIST100?',\n    fontsize = 15\n)\nbplt.set_xlabel(xlabel = '')\nbplt.set_ylabel(ylabel = '')\nplt.show()\n\n\n\n\nScatterplot (Average Returns vs Standard Deviations):\n\n\nday = result['DAY']\nr_mean_x = result['r_mean']\nr_std_y = result['r_std']\n\nfig = plt.figure(figsize = (10, 7))\nsplt = sns.scatterplot(\n    x = 'r_mean',\n    y = 'r_std',\n    data = result,\n    s = 150,\n    alpha = .5\n)\nfor i, day in enumerate (day):\n    plt.annotate(\n        day, (r_mean_x[i], r_std_y[i])\n    )\nsplt.set_xlabel(xlabel = 'Average', size = 8)\nsplt.set_ylabel(ylabel = 'Standard Deviation', size = 8)\nplt.show()"
  },
  {
    "objectID": "posts/20221115_post2/index.html",
    "href": "posts/20221115_post2/index.html",
    "title": "Key Steps Before Building a Model [Eligibility Prediction for Loan]",
    "section": "",
    "text": "I obtained the dataset for this post from Kaggle. You can also access it by downloading the post2.csv file from here.\n\nLoan_ID: Loan_ID\nGender: Male/Female\nMarried: Applicant married (Y/N)\nDependents: Number of dependents\nEducation: Applicant Education (Graduate/Under Graduate)\nSelf_Employed: Self employed (Y/N)\nApplicantIncome: Applicant income\nCoapplicantIncome: Coapplicant income\nLoanAmount: Loan amount in thousands\nLoan_Amount_Term: Term of loan in months\nCredit_History: Credit history meets guidelines\nProperty_Area: Urban/Semi Urban/Rural\nLoan_Status: (Target) Loan approved (Y/N)\n\n\nR\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\ndt_loan <- read.csv(\"data.csv\")\n\n#head(dt_loan)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoan_ID\nGender\nMarried\nDependents\nEducation\nSelf_Employed\nApplicantIncome\nCoapplicantIncome\nLoanAmount\nLoan_Amount_Term\nCredit_History\nProperty_Area\nLoan_Status\n\n\n\n\nLP001002\nMale\nNo\n0\nGraduate\nNo\n5849\n0\nNA\n360\n1\nUrban\nY\n\n\nLP001003\nMale\nYes\n1\nGraduate\nNo\n4583\n1508\n128\n360\n1\nRural\nN\n\n\nLP001005\nMale\nYes\n0\nGraduate\nYes\n3000\n0\n66\n360\n1\nUrban\nY\n\n\nLP001006\nMale\nYes\n0\nNot Graduate\nNo\n2583\n2358\n120\n360\n1\nUrban\nY\n\n\nLP001008\nMale\nNo\n0\nGraduate\nNo\n6000\n0\n141\n360\n1\nUrban\nY\n\n\nLP001011\nMale\nYes\n2\nGraduate\nYes\n5417\n4196\n267\n360\n1\nUrban\nY\n\n\n\n\n\n\nThe total number of rows:\n\n\nnrow(dt_loan)\n\n[1] 614\n\n\n\nAre there customers with similar IDs? If so which one or which ones?\n\n\nlength(unique(dt_loan$Loan_ID)) == nrow(dt_loan)\n\n[1] TRUE\n\n\n\nGender: Male/Female\n\n\ndt_loan %>%\ncount(Gender) %>%\nmutate(p = n / sum(n) * 100)\n\n  Gender   n         p\n1         13  2.117264\n2 Female 112 18.241042\n3   Male 489 79.641694\n\ndt_loan %>%\ncount(Gender) %>%\nggplot(aes(x = Gender, y = n, fill = Gender)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe gender of 13 customers is unknown. The majority of applicants are males.\nRemove 13 customers whose gender is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Gender != \"\")\n\nnrow(dt_loan)\n\n[1] 601\n\n\n\nMarried: Applicant married (Y/N)\n\n\ndt_loan %>%\ncount(Married) %>%\nmutate(p = n / sum(n) * 100)\n\n  Married   n          p\n1           3  0.4991681\n2      No 210 34.9417637\n3     Yes 388 64.5590682\n\ndt_loan %>%\ncount(Married) %>%\nggplot(aes(x = Married, y = n, fill = Married)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIt is unknown whether the 3 customers are married. One-third of those who apply are married.\nRemove 3 customers whose marital status is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Married != \"\")\n\nnrow(dt_loan)\n\n[1] 598\n\n\n\nDependents: Number of dependents\n\n\ndt_loan %>%\ncount(Dependents) %>%\nmutate(p = n / sum(n) * 100)\n\n  Dependents   n         p\n1             12  2.006689\n2          0 338 56.521739\n3          1 101 16.889632\n4          2  99 16.555184\n5         3+  48  8.026756\n\ndt_loan %>%\ncount(Dependents) %>%\nggplot(aes(x = Dependents, y = n, fill = Dependents)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe dependent information of 12 customers is unknown. A little more than half of those who applied have no dependents.\nRemove 12 customers who do not have information about their dependents from the data set.\nc\n\nEducation: Applicant Education (Graduate/Under Graduate)\n\n\ndt_loan %>%\ncount(Education) %>%\nmutate(p = n / sum(n) * 100)\n\n     Education   n       p\n1     Graduate 465 77.7592\n2 Not Graduate 133 22.2408\n\ndt_loan %>%\ncount(Education) %>%\nggplot(aes(x = Education, y = n, fill = Education)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIn this category, all customers have educational information. Most applicants hold graduate degrees.\n\nSelf_Employed: Self employed (Y/N)\n\n\ndt_loan %>%\ncount(Self_Employed) %>%\nmutate(p = n / sum(n) * 100)\n\n  Self_Employed   n         p\n1                32  5.351171\n2            No 488 81.605351\n3           Yes  78 13.043478\n\ndt_loan %>%\ncount(Self_Employed) %>%\nggplot(aes(x = Self_Employed, y = n, fill = Self_Employed)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThere is no information on whether 32 customers are self-employed. The vast majority of applicants are not self-employed.\nRemove 32 customers from the dataset, whether or not they are self-employed.\n\ndt_loan <- dt_loan %>%\nfilter(Self_Employed != \"\")\n\nnrow(dt_loan)\n\n[1] 566\n\n\n\nApplicantIncome: Applicant income\n\n\ndt_loan %>%\nsummarise(\n  min = min(ApplicantIncome),\n  max = max(ApplicantIncome),\n  mean = mean(ApplicantIncome),\n  median = median(ApplicantIncome),\n  sd = sd(ApplicantIncome)\n)\n\n  min   max     mean median       sd\n1 150 81000 5259.972 3839.5 5412.902\n\nggplot(dt_loan, aes(x = ApplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\nCoapplicantIncome: Coapplicant income\n\n\ndt_loan %>%\nsummarise(\n  min = min(CoapplicantIncome),\n  max = max(CoapplicantIncome),\n  mean = mean(CoapplicantIncome),\n  median = median(CoapplicantIncome),\n  sd = sd(CoapplicantIncome)\n)\n\n  min   max     mean median       sd\n1   0 33837 1579.147   1149 2507.244\n\nggplot(dt_loan, aes(x = CoapplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\nLoanAmount: Loan amount in thousands\n\n\ndt_loan %>%\nsummarise(\n  min = min(LoanAmount),\n  max = max(LoanAmount),\n  mean = mean(LoanAmount),\n  median = median(LoanAmount),\n  sd = sd(LoanAmount)\n)\n\n  min max mean median sd\n1  NA  NA   NA     NA NA\n\nggplot(dt_loan, aes(x = LoanAmount)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\nLoan_Amount_Term: Term of loan in months\n\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nmutate(p = n / sum(n) * 100)\n\n   Loan_Amount_Term   n          p\n1                12   1  0.1766784\n2                36   2  0.3533569\n3                60   2  0.3533569\n4                84   4  0.7067138\n5               120   3  0.5300353\n6               180  39  6.8904594\n7               240   3  0.5300353\n8               300  12  2.1201413\n9               360 473 83.5689046\n10              480  14  2.4734982\n11               NA  13  2.2968198\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nggplot(aes(x = Loan_Amount_Term, y = n, fill = Loan_Amount_Term)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\nCredit_History: Credit history meets guidelines\n\n\ndt_loan %>%\ncount(Credit_History) %>%\nmutate(p = n / sum(n) * 100)\n\n  Credit_History   n         p\n1              0  85 15.017668\n2              1 438 77.385159\n3             NA  43  7.597173\n\ndt_loan %>%\ncount(Credit_History) %>%\nggplot(aes(x = Credit_History, y = n, fill = Credit_History)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\nProperty_Area: Urban/Semi Urban/Rural\n\n\ndt_loan %>%\ncount(Property_Area) %>%\nmutate(p = n / sum(n) * 100)\n\n  Property_Area   n        p\n1         Rural 165 29.15194\n2     Semiurban 215 37.98587\n3         Urban 186 32.86219\n\ndt_loan %>%\ncount(Property_Area) %>%\nggplot(aes(x = Property_Area, y = n, fill = Property_Area)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\nLoan_Status: (Target) Loan approved (Y/N)\n\n\ndt_loan %>%\ncount(Loan_Status) %>%\nmutate(p = n / sum(n) * 100)\n\n  Loan_Status   n        p\n1           N 178 31.44876\n2           Y 388 68.55124\n\ndt_loan %>%\ncount(Loan_Status) %>%\nggplot(aes(x = Loan_Status, y = n, fill = Loan_Status)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/20221116_post2/index.html",
    "href": "posts/20221116_post2/index.html",
    "title": "Key Steps Before Building a Model [Eligibility Prediction for Loan]",
    "section": "",
    "text": "I obtained the dataset for this post from Kaggle. You can also access it by downloading the post2.csv file from here.\n\nLoan_ID: Loan_ID\nGender: Male/Female\nMarried: Applicant married (Y/N)\nDependents: Number of dependents\nEducation: Applicant Education (Graduate/Under Graduate)\nSelf_Employed: Self employed (Y/N)\nApplicantIncome: Applicant income\nCoapplicantIncome: Coapplicant income\nLoanAmount: Loan amount in thousands\nLoan_Amount_Term: Term of loan in months\nCredit_History: Credit history meets guidelines\nProperty_Area: Urban/Semi Urban/Rural\nLoan_Status: (Target) Loan approved (Y/N)\n\n\nR\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\ndt_loan <- read.csv(\"data.csv\")\n\n#head(dt_loan)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoan_ID\nGender\nMarried\nDependents\nEducation\nSelf_Employed\nApplicantIncome\nCoapplicantIncome\nLoanAmount\nLoan_Amount_Term\nCredit_History\nProperty_Area\nLoan_Status\n\n\n\n\nLP001002\nMale\nNo\n0\nGraduate\nNo\n5849\n0\nNA\n360\n1\nUrban\nY\n\n\nLP001003\nMale\nYes\n1\nGraduate\nNo\n4583\n1508\n128\n360\n1\nRural\nN\n\n\nLP001005\nMale\nYes\n0\nGraduate\nYes\n3000\n0\n66\n360\n1\nUrban\nY\n\n\nLP001006\nMale\nYes\n0\nNot Graduate\nNo\n2583\n2358\n120\n360\n1\nUrban\nY\n\n\nLP001008\nMale\nNo\n0\nGraduate\nNo\n6000\n0\n141\n360\n1\nUrban\nY\n\n\nLP001011\nMale\nYes\n2\nGraduate\nYes\n5417\n4196\n267\n360\n1\nUrban\nY\n\n\n\n\n\n\nThe total number of rows:\n\nnrow(dt_loan)\n\n[1] 614\n\n\n\n\nAre there customers with similar IDs? If so which one or which ones?\n\nlength(unique(dt_loan$Loan_ID)) == nrow(dt_loan)\n\n[1] TRUE\n\n\n\n\nGender: Male/Female\n\ndt_loan %>%\ncount(Gender) %>%\nmutate(p = n / sum(n) * 100)\n\n  Gender   n         p\n1         13  2.117264\n2 Female 112 18.241042\n3   Male 489 79.641694\n\ndt_loan %>%\ncount(Gender) %>%\nggplot(aes(x = Gender, y = n, fill = Gender)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe gender of 13 customers is unknown. The majority of applicants are males.\nRemove 13 customers whose gender is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Gender != \"\")\n\nnrow(dt_loan)\n\n[1] 601\n\n\n\n\nMarried: Applicant married (Y/N)\n\ndt_loan %>%\ncount(Married) %>%\nmutate(p = n / sum(n) * 100)\n\n  Married   n          p\n1           3  0.4991681\n2      No 210 34.9417637\n3     Yes 388 64.5590682\n\ndt_loan %>%\ncount(Married) %>%\nggplot(aes(x = Married, y = n, fill = Married)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIt is unknown whether the 3 customers are married. One-third of those who apply are married.\nRemove 3 customers whose marital status is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Married != \"\")\n\nnrow(dt_loan)\n\n[1] 598\n\n\n\n\nDependents: Number of dependents\n\ndt_loan %>%\ncount(Dependents) %>%\nmutate(p = n / sum(n) * 100)\n\n  Dependents   n         p\n1             12  2.006689\n2          0 338 56.521739\n3          1 101 16.889632\n4          2  99 16.555184\n5         3+  48  8.026756\n\ndt_loan %>%\ncount(Dependents) %>%\nggplot(aes(x = Dependents, y = n, fill = Dependents)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe dependent information of 12 customers is unknown. A little more than half of those who applied have no dependents.\nRemove 12 customers who do not have information about their dependents from the data set.\n\ndt_loan <- dt_loan %>%\nfilter(Dependents != \"\")\n\nnrow(dt_loan)\n\n[1] 586\n\n\n\n\nEducation: Applicant Education (Graduate/Under Graduate)\n\ndt_loan %>%\ncount(Education) %>%\nmutate(p = n / sum(n) * 100)\n\n     Education   n        p\n1     Graduate 457 77.98635\n2 Not Graduate 129 22.01365\n\ndt_loan %>%\ncount(Education) %>%\nggplot(aes(x = Education, y = n, fill = Education)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIn this category, all customers have educational information. Most applicants hold graduate degrees.\n\n\nSelf_Employed: Self employed (Y/N)\n\ndt_loan %>%\ncount(Self_Employed) %>%\nmutate(p = n / sum(n) * 100)\n\n  Self_Employed   n         p\n1                32  5.460751\n2            No 478 81.569966\n3           Yes  76 12.969283\n\ndt_loan %>%\ncount(Self_Employed) %>%\nggplot(aes(x = Self_Employed, y = n, fill = Self_Employed)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThere is no information on whether 32 customers are self-employed. The vast majority of applicants are not self-employed.\nRemove 32 customers from the dataset, whether or not they are self-employed.\n\ndt_loan <- dt_loan %>%\nfilter(Self_Employed != \"\")\n\nnrow(dt_loan)\n\n[1] 554\n\n\n\n\nApplicantIncome: Applicant income\n\ndt_loan %>%\nsummarise(\n  min = min(ApplicantIncome),\n  max = max(ApplicantIncome),\n  mean = mean(ApplicantIncome),\n  median = median(ApplicantIncome),\n  sd = sd(ApplicantIncome)\n)\n\n  min   max    mean median       sd\n1 150 81000 5267.06 3839.5 5455.163\n\nggplot(dt_loan, aes(x = ApplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\n\nCoapplicantIncome: Coapplicant income\n\ndt_loan %>%\nsummarise(\n  min = min(CoapplicantIncome),\n  max = max(CoapplicantIncome),\n  mean = mean(CoapplicantIncome),\n  median = median(CoapplicantIncome),\n  sd = sd(CoapplicantIncome)\n)\n\n  min   max     mean median       sd\n1   0 33837 1585.576   1149 2524.485\n\nggplot(dt_loan, aes(x = CoapplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\n\nLoanAmount: Loan amount in thousands\n\ndt_loan %>%\nsummarise(\n  min = min(LoanAmount),\n  max = max(LoanAmount),\n  mean = mean(LoanAmount),\n  median = median(LoanAmount),\n  sd = sd(LoanAmount)\n)\n\n  min max mean median sd\n1  NA  NA   NA     NA NA\n\nggplot(dt_loan, aes(x = LoanAmount)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\nWe are unable to calculate summary statistics because some customers do not have a loan amount or LoanAmount.\n\ndt_loan <- dt_loan %>%\nfilter(LoanAmount != \"\")\n\ndt_loan %>%\nsummarise(\n  min = min(LoanAmount),\n  max = max(LoanAmount),\n  mean = mean(LoanAmount),\n  median = median(LoanAmount),\n  sd = sd(LoanAmount)\n)\n\n  min max     mean median       sd\n1   9 650 144.9178    127 82.50775\n\nnrow(dt_loan)\n\n[1] 535\n\n\n\n\nLoan_Amount_Term: Term of loan in months\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nmutate(p = n / sum(n) * 100)\n\n   Loan_Amount_Term   n          p\n1                12   1  0.1869159\n2                36   2  0.3738318\n3                60   2  0.3738318\n4                84   4  0.7476636\n5               120   3  0.5607477\n6               180  36  6.7289720\n7               240   3  0.5607477\n8               300  12  2.2429907\n9               360 447 83.5514019\n10              480  13  2.4299065\n11               NA  12  2.2429907\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nggplot(aes(x = Loan_Amount_Term, y = n, fill = Loan_Amount_Term)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n12 customers do not have Loan_Amount_Term information.\n\ndt_loan <- dt_loan %>%\nfilter(!is.na(Loan_Amount_Term))\n\nnrow(dt_loan)\n\n[1] 523\n\n\n\n\nCredit_History: Credit history meets guidelines\n\ndt_loan %>%\ncount(Credit_History) %>%\nmutate(p = n / sum(n) * 100)\n\n  Credit_History   n         p\n1              0  70 13.384321\n2              1 410 78.393881\n3             NA  43  8.221797\n\ndt_loan %>%\ncount(Credit_History) %>%\nggplot(aes(x = Credit_History, y = n, fill = Credit_History)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\n\nProperty_Area: Urban/Semi Urban/Rural\n\ndt_loan %>%\ncount(Property_Area) %>%\nmutate(p = n / sum(n) * 100)\n\n  Property_Area   n        p\n1         Rural 153 29.25430\n2     Semiurban 205 39.19694\n3         Urban 165 31.54876\n\ndt_loan %>%\ncount(Property_Area) %>%\nggplot(aes(x = Property_Area, y = n, fill = Property_Area)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\n\nLoan_Status: (Target) Loan approved (Y/N)\n\ndt_loan %>%\ncount(Loan_Status) %>%\nmutate(p = n / sum(n) * 100)\n\n  Loan_Status   n        p\n1           N 156 29.82792\n2           Y 367 70.17208\n\ndt_loan %>%\ncount(Loan_Status) %>%\nggplot(aes(x = Loan_Status, y = n, fill = Loan_Status)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/20221116_post2/index.html#the-total-number-of-rows",
    "href": "posts/20221116_post2/index.html#the-total-number-of-rows",
    "title": "Key Steps Before Building a Model [Eligibility Prediction for Loan]",
    "section": "The total number of rows:",
    "text": "The total number of rows:\n\nnrow(dt_loan)\n\n[1] 614\n\n\n\nAre there customers with similar IDs? If so which one or which ones?\n\n\nlength(unique(dt_loan$Loan_ID)) == nrow(dt_loan)\n\n[1] TRUE\n\n\n\nGender: Male/Female\n\n\ndt_loan %>%\ncount(Gender) %>%\nmutate(p = n / sum(n) * 100)\n\n  Gender   n         p\n1         13  2.117264\n2 Female 112 18.241042\n3   Male 489 79.641694\n\ndt_loan %>%\ncount(Gender) %>%\nggplot(aes(x = Gender, y = n, fill = Gender)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe gender of 13 customers is unknown. The majority of applicants are males.\nRemove 13 customers whose gender is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Gender != \"\")\n\nnrow(dt_loan)\n\n[1] 601\n\n\n\nMarried: Applicant married (Y/N)\n\n\ndt_loan %>%\ncount(Married) %>%\nmutate(p = n / sum(n) * 100)\n\n  Married   n          p\n1           3  0.4991681\n2      No 210 34.9417637\n3     Yes 388 64.5590682\n\ndt_loan %>%\ncount(Married) %>%\nggplot(aes(x = Married, y = n, fill = Married)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIt is unknown whether the 3 customers are married. One-third of those who apply are married.\nRemove 3 customers whose marital status is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Married != \"\")\n\nnrow(dt_loan)\n\n[1] 598\n\n\n\nDependents: Number of dependents\n\n\ndt_loan %>%\ncount(Dependents) %>%\nmutate(p = n / sum(n) * 100)\n\n  Dependents   n         p\n1             12  2.006689\n2          0 338 56.521739\n3          1 101 16.889632\n4          2  99 16.555184\n5         3+  48  8.026756\n\ndt_loan %>%\ncount(Dependents) %>%\nggplot(aes(x = Dependents, y = n, fill = Dependents)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe dependent information of 12 customers is unknown. A little more than half of those who applied have no dependents.\nRemove 12 customers who do not have information about their dependents from the data set.\nc\n\nEducation: Applicant Education (Graduate/Under Graduate)\n\n\ndt_loan %>%\ncount(Education) %>%\nmutate(p = n / sum(n) * 100)\n\n     Education   n       p\n1     Graduate 465 77.7592\n2 Not Graduate 133 22.2408\n\ndt_loan %>%\ncount(Education) %>%\nggplot(aes(x = Education, y = n, fill = Education)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIn this category, all customers have educational information. Most applicants hold graduate degrees.\n\nSelf_Employed: Self employed (Y/N)\n\n\ndt_loan %>%\ncount(Self_Employed) %>%\nmutate(p = n / sum(n) * 100)\n\n  Self_Employed   n         p\n1                32  5.351171\n2            No 488 81.605351\n3           Yes  78 13.043478\n\ndt_loan %>%\ncount(Self_Employed) %>%\nggplot(aes(x = Self_Employed, y = n, fill = Self_Employed)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThere is no information on whether 32 customers are self-employed. The vast majority of applicants are not self-employed.\nRemove 32 customers from the dataset, whether or not they are self-employed.\n\ndt_loan <- dt_loan %>%\nfilter(Self_Employed != \"\")\n\nnrow(dt_loan)\n\n[1] 566\n\n\n\nApplicantIncome: Applicant income\n\n\ndt_loan %>%\nsummarise(\n  min = min(ApplicantIncome),\n  max = max(ApplicantIncome),\n  mean = mean(ApplicantIncome),\n  median = median(ApplicantIncome),\n  sd = sd(ApplicantIncome)\n)\n\n  min   max     mean median       sd\n1 150 81000 5259.972 3839.5 5412.902\n\nggplot(dt_loan, aes(x = ApplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\nCoapplicantIncome: Coapplicant income\n\n\ndt_loan %>%\nsummarise(\n  min = min(CoapplicantIncome),\n  max = max(CoapplicantIncome),\n  mean = mean(CoapplicantIncome),\n  median = median(CoapplicantIncome),\n  sd = sd(CoapplicantIncome)\n)\n\n  min   max     mean median       sd\n1   0 33837 1579.147   1149 2507.244\n\nggplot(dt_loan, aes(x = CoapplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\nLoanAmount: Loan amount in thousands\n\n\ndt_loan %>%\nsummarise(\n  min = min(LoanAmount),\n  max = max(LoanAmount),\n  mean = mean(LoanAmount),\n  median = median(LoanAmount),\n  sd = sd(LoanAmount)\n)\n\n  min max mean median sd\n1  NA  NA   NA     NA NA\n\nggplot(dt_loan, aes(x = LoanAmount)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\nLoan_Amount_Term: Term of loan in months\n\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nmutate(p = n / sum(n) * 100)\n\n   Loan_Amount_Term   n          p\n1                12   1  0.1766784\n2                36   2  0.3533569\n3                60   2  0.3533569\n4                84   4  0.7067138\n5               120   3  0.5300353\n6               180  39  6.8904594\n7               240   3  0.5300353\n8               300  12  2.1201413\n9               360 473 83.5689046\n10              480  14  2.4734982\n11               NA  13  2.2968198\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nggplot(aes(x = Loan_Amount_Term, y = n, fill = Loan_Amount_Term)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\nCredit_History: Credit history meets guidelines\n\n\ndt_loan %>%\ncount(Credit_History) %>%\nmutate(p = n / sum(n) * 100)\n\n  Credit_History   n         p\n1              0  85 15.017668\n2              1 438 77.385159\n3             NA  43  7.597173\n\ndt_loan %>%\ncount(Credit_History) %>%\nggplot(aes(x = Credit_History, y = n, fill = Credit_History)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\nProperty_Area: Urban/Semi Urban/Rural\n\n\ndt_loan %>%\ncount(Property_Area) %>%\nmutate(p = n / sum(n) * 100)\n\n  Property_Area   n        p\n1         Rural 165 29.15194\n2     Semiurban 215 37.98587\n3         Urban 186 32.86219\n\ndt_loan %>%\ncount(Property_Area) %>%\nggplot(aes(x = Property_Area, y = n, fill = Property_Area)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\nLoan_Status: (Target) Loan approved (Y/N)\n\n\ndt_loan %>%\ncount(Loan_Status) %>%\nmutate(p = n / sum(n) * 100)\n\n  Loan_Status   n        p\n1           N 178 31.44876\n2           Y 388 68.55124\n\ndt_loan %>%\ncount(Loan_Status) %>%\nggplot(aes(x = Loan_Status, y = n, fill = Loan_Status)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/20221118_post2/index.html",
    "href": "posts/20221118_post2/index.html",
    "title": "Key Steps Before Building a Model [Eligibility Prediction for Loan]",
    "section": "",
    "text": "I obtained the dataset for this post from Kaggle. You can also access it by downloading the post2.csv file from here.\n\nLoan_ID: Loan_ID\nGender: Male/Female\nMarried: Applicant married (Y/N)\nDependents: Number of dependents\nEducation: Applicant Education (Graduate/Under Graduate)\nSelf_Employed: Self employed (Y/N)\nApplicantIncome: Applicant income\nCoapplicantIncome: Coapplicant income\nLoanAmount: Loan amount in thousands\nLoan_Amount_Term: Term of loan in months\nCredit_History: Credit history meets guidelines\nProperty_Area: Urban/Semi Urban/Rural\nLoan_Status: (Target) Loan approved (Y/N)\n\n\nR\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\ndt_loan <- read.csv(\"data.csv\")\n\n#head(dt_loan)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoan_ID\nGender\nMarried\nDependents\nEducation\nSelf_Employed\nApplicantIncome\nCoapplicantIncome\nLoanAmount\nLoan_Amount_Term\nCredit_History\nProperty_Area\nLoan_Status\n\n\n\n\nLP001002\nMale\nNo\n0\nGraduate\nNo\n5849\n0\nNA\n360\n1\nUrban\nY\n\n\nLP001003\nMale\nYes\n1\nGraduate\nNo\n4583\n1508\n128\n360\n1\nRural\nN\n\n\nLP001005\nMale\nYes\n0\nGraduate\nYes\n3000\n0\n66\n360\n1\nUrban\nY\n\n\nLP001006\nMale\nYes\n0\nNot Graduate\nNo\n2583\n2358\n120\n360\n1\nUrban\nY\n\n\nLP001008\nMale\nNo\n0\nGraduate\nNo\n6000\n0\n141\n360\n1\nUrban\nY\n\n\nLP001011\nMale\nYes\n2\nGraduate\nYes\n5417\n4196\n267\n360\n1\nUrban\nY\n\n\n\n\n\n\nThe total number of rows:\n\nnrow(dt_loan)\n\n[1] 614\n\n\n\n\nAre there customers with similar IDs? If so which one or which ones?\n\nlength(unique(dt_loan$Loan_ID)) == nrow(dt_loan)\n\n[1] TRUE\n\n\n\n\nGender: Male/Female\n\ndt_loan %>%\ncount(Gender) %>%\nmutate(p = n / sum(n) * 100)\n\n  Gender   n         p\n1         13  2.117264\n2 Female 112 18.241042\n3   Male 489 79.641694\n\ndt_loan %>%\ncount(Gender) %>%\nggplot(aes(x = Gender, y = n, fill = Gender)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe gender of 13 customers is unknown. The majority of applicants are males.\nRemove 13 customers whose gender is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Gender != \"\")\n\nnrow(dt_loan)\n\n[1] 601\n\n\n\n\nMarried: Applicant married (Y/N)\n\ndt_loan %>%\ncount(Married) %>%\nmutate(p = n / sum(n) * 100)\n\n  Married   n          p\n1           3  0.4991681\n2      No 210 34.9417637\n3     Yes 388 64.5590682\n\ndt_loan %>%\ncount(Married) %>%\nggplot(aes(x = Married, y = n, fill = Married)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIt is unknown whether the 3 customers are married. One-third of those who apply are married.\nRemove 3 customers whose marital status is unknown from the dataset.\n\ndt_loan <- dt_loan %>%\nfilter(Married != \"\")\n\nnrow(dt_loan)\n\n[1] 598\n\n\n\n\nDependents: Number of dependents\n\ndt_loan %>%\ncount(Dependents) %>%\nmutate(p = n / sum(n) * 100)\n\n  Dependents   n         p\n1             12  2.006689\n2          0 338 56.521739\n3          1 101 16.889632\n4          2  99 16.555184\n5         3+  48  8.026756\n\ndt_loan %>%\ncount(Dependents) %>%\nggplot(aes(x = Dependents, y = n, fill = Dependents)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThe dependent information of 12 customers is unknown. A little more than half of those who applied have no dependents.\nRemove 12 customers who do not have information about their dependents from the data set.\n\ndt_loan <- dt_loan %>%\nfilter(Dependents != \"\")\n\nnrow(dt_loan)\n\n[1] 586\n\n\n\n\nEducation: Applicant Education (Graduate/Under Graduate)\n\ndt_loan %>%\ncount(Education) %>%\nmutate(p = n / sum(n) * 100)\n\n     Education   n        p\n1     Graduate 457 77.98635\n2 Not Graduate 129 22.01365\n\ndt_loan %>%\ncount(Education) %>%\nggplot(aes(x = Education, y = n, fill = Education)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nIn this category, all customers have educational information. Most applicants hold graduate degrees.\n\n\nSelf_Employed: Self employed (Y/N)\n\ndt_loan %>%\ncount(Self_Employed) %>%\nmutate(p = n / sum(n) * 100)\n\n  Self_Employed   n         p\n1                32  5.460751\n2            No 478 81.569966\n3           Yes  76 12.969283\n\ndt_loan %>%\ncount(Self_Employed) %>%\nggplot(aes(x = Self_Employed, y = n, fill = Self_Employed)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\nThere is no information on whether 32 customers are self-employed. The vast majority of applicants are not self-employed.\nRemove 32 customers from the dataset, whether or not they are self-employed.\n\ndt_loan <- dt_loan %>%\nfilter(Self_Employed != \"\")\n\nnrow(dt_loan)\n\n[1] 554\n\n\n\n\nApplicantIncome: Applicant income\n\ndt_loan %>%\nsummarise(\n  min = min(ApplicantIncome),\n  max = max(ApplicantIncome),\n  mean = mean(ApplicantIncome),\n  median = median(ApplicantIncome),\n  sd = sd(ApplicantIncome)\n)\n\n  min   max    mean median       sd\n1 150 81000 5267.06 3839.5 5455.163\n\nggplot(dt_loan, aes(x = ApplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\n\nCoapplicantIncome: Coapplicant income\n\ndt_loan %>%\nsummarise(\n  min = min(CoapplicantIncome),\n  max = max(CoapplicantIncome),\n  mean = mean(CoapplicantIncome),\n  median = median(CoapplicantIncome),\n  sd = sd(CoapplicantIncome)\n)\n\n  min   max     mean median       sd\n1   0 33837 1585.576   1149 2524.485\n\nggplot(dt_loan, aes(x = CoapplicantIncome)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\n\n\nLoanAmount: Loan amount in thousands\n\ndt_loan %>%\nsummarise(\n  min = min(LoanAmount),\n  max = max(LoanAmount),\n  mean = mean(LoanAmount),\n  median = median(LoanAmount),\n  sd = sd(LoanAmount)\n)\n\n  min max mean median sd\n1  NA  NA   NA     NA NA\n\nggplot(dt_loan, aes(x = LoanAmount)) +\ngeom_histogram(aes(y = ..density..), fill = \"orange\") +\ngeom_density(size = 1) +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\") +\ntheme(axis.text.y = element_blank())\n\n\n\n\nWe are unable to calculate summary statistics because some customers do not have a LoanAmount.\n\ndt_loan <- dt_loan %>%\nfilter(LoanAmount != \"\")\n\ndt_loan %>%\nsummarise(\n  min = min(LoanAmount),\n  max = max(LoanAmount),\n  mean = mean(LoanAmount),\n  median = median(LoanAmount),\n  sd = sd(LoanAmount)\n)\n\n  min max     mean median       sd\n1   9 650 144.9178    127 82.50775\n\nnrow(dt_loan)\n\n[1] 535\n\n\n\n\nLoan_Amount_Term: Term of loan in months\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nmutate(p = n / sum(n) * 100)\n\n   Loan_Amount_Term   n          p\n1                12   1  0.1869159\n2                36   2  0.3738318\n3                60   2  0.3738318\n4                84   4  0.7476636\n5               120   3  0.5607477\n6               180  36  6.7289720\n7               240   3  0.5607477\n8               300  12  2.2429907\n9               360 447 83.5514019\n10              480  13  2.4299065\n11               NA  12  2.2429907\n\ndt_loan %>%\ncount(Loan_Amount_Term) %>%\nggplot(aes(x = Loan_Amount_Term, y = n, fill = Loan_Amount_Term)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n12 customers do not have Loan_Amount_Term information.\n\ndt_loan <- dt_loan %>%\nfilter(!is.na(Loan_Amount_Term))\n\nnrow(dt_loan)\n\n[1] 523\n\n\n\n\nCredit_History: Credit history meets guidelines\n\ndt_loan %>%\ncount(Credit_History) %>%\nmutate(p = n / sum(n) * 100)\n\n  Credit_History   n         p\n1              0  70 13.384321\n2              1 410 78.393881\n3             NA  43  8.221797\n\ndt_loan %>%\ncount(Credit_History) %>%\nggplot(aes(x = Credit_History, y = n, fill = Credit_History)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\n\nProperty_Area: Urban/Semi Urban/Rural\n\ndt_loan %>%\ncount(Property_Area) %>%\nmutate(p = n / sum(n) * 100)\n\n  Property_Area   n        p\n1         Rural 153 29.25430\n2     Semiurban 205 39.19694\n3         Urban 165 31.54876\n\ndt_loan %>%\ncount(Property_Area) %>%\nggplot(aes(x = Property_Area, y = n, fill = Property_Area)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")\n\n\n\n\n\n\nLoan_Status: (Target) Loan approved (Y/N)\n\ndt_loan %>%\ncount(Loan_Status) %>%\nmutate(p = n / sum(n) * 100)\n\n  Loan_Status   n        p\n1           N 156 29.82792\n2           Y 367 70.17208\n\ndt_loan %>%\ncount(Loan_Status) %>%\nggplot(aes(x = Loan_Status, y = n, fill = Loan_Status)) +\ngeom_col() +\ntheme_fivethirtyeight() +\ntheme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/20221119_post2/index.html",
    "href": "posts/20221119_post2/index.html",
    "title": "Dinamik Zaman Bükme ile Zaman Serisi Kümeleme Analizi: SASA Hissesi",
    "section": "",
    "text": "Reuters’tan elde ettiğim SASA verilerine buradan post2.xlsx dosyasını indirerek ulaşabilirsiniz. R ve Python kodlarını çalışmanın sonunda vermiş olacağım.\nPortföyünde SASA olanların ve hatta SASA olmasa bile borsa yatırımı ile ilgilenenlerin seçtiğim hisse için elbette yorumları olacaktır. Burada yapacağım çalışma, sadece fiyat hareketlerini (biraz daha teknik anlamda zaman serisini) baz alarak ve literatürdeki yöntemleri de dahil ederek yön olasılıkları bulmayı amaçlamaktadır. Amacım kesinlikle bir yatırım tavsiyesi vermek olmamakla beraber aslında yatırım tavsiyesinden de ötesini verebilmektir. O da teknik bir bakış açısı.\nÇalışmayı şöyle tasarladım: Günlük bazda belli bir sayıda olan zaman serisini eşit parçalara böleceğiz. Serilerin geçmişte de benzer (buradaki benzerlik tamamıyla aynı hareketleri yapmak anlamı taşımamaktadır) hareketler ortaya koyduğu varsayımıyla benzer serileri aynı kümede bir araya getireceğiz. Ardından belli bir sayıda örüntü elde edecek ve bu örüntüler arası geçiş olasılıklarını hesaplayacağız. Hesapladığımız bu olasılıklar ile nihayet hisse için yön tayin etmiş olacağız.\nSASA hissesinin 2003 itibarıyla olan genel görünümüne bakalım.\n\n\n\n\n\n\n\n\n\n\n\nSerileri eşit parçalara ayırmanın bile ayrı bir çalışma alanı olması gerektiğine inansam da bu çalışmada seriyi 50’lik dilimlere ayıracağız. Ancak elimizde 4991 satır bulunmaktadır. Bu da 50 sayısına tam bölünmeyecektir. 50 ile bölünebilmesi için sayının 00 veya 50 ile bitmesi gerekiyor. Bu durumda ilk 4950 satırı alabiliriz. Bu durumda ana seriden elde edilmiş 99 adet alt seri olacaktır.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntarih\nkapanis\nt\ngrup\n\n\n\n\n2003-01-02\n0.0875887\n1\nG1\n\n\n2003-01-03\n0.0890485\n2\nG1\n\n\n2003-01-06\n0.0832093\n3\nG1\n\n\n2003-01-07\n0.0773700\n4\nG1\n\n\n2003-01-08\n0.0832093\n5\nG1\n\n\n\n\n\n\n\n\ntarih\nkapanis\nt\ngrup\n\n\n\n\n2022-09-16\n55.15\n4946\nG99\n\n\n2022-09-19\n53.40\n4947\nG99\n\n\n2022-09-20\n58.60\n4948\nG99\n\n\n2022-09-21\n57.40\n4949\nG99\n\n\n2022-09-22\n58.05\n4950\nG99\n\n\n\n\n\nSerileri normalize ederek ilerleyeceğiz. Böylece birbirinden oldukça farklı olan fiyatları her bir grup için 0-1 arasına dahil etmiş olacağız.\n\\(X_{normalize} = \\frac{X - X_{min}}{X_{maks} - X_{min}}\\)\n\n\n\nAşağıda, normalize edilen grupların ilk 10 satırını görüyorsunuz.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt\nG1\nG2\nG3\nG4\nG5\nG6\nG7\nG8\nG9\nG10\nG11\nG12\nG13\nG14\nG15\nG16\nG17\nG18\nG19\nG20\nG21\nG22\nG23\nG24\nG25\nG26\nG27\nG28\nG29\nG30\nG31\nG32\nG33\nG34\nG35\nG36\nG37\nG38\nG39\nG40\nG41\nG42\nG43\nG44\nG45\nG46\nG47\nG48\nG49\nG50\nG51\nG52\nG53\nG54\nG55\nG56\nG57\nG58\nG59\nG60\nG61\nG62\nG63\nG64\nG65\nG66\nG67\nG68\nG69\nG70\nG71\nG72\nG73\nG74\nG75\nG76\nG77\nG78\nG79\nG80\nG81\nG82\nG83\nG84\nG85\nG86\nG87\nG88\nG89\nG90\nG91\nG92\nG93\nG94\nG95\nG96\nG97\nG98\nG99\n\n\n\n\n1\n0.5000000\n0.2666667\n1.0000000\n0.60\n0.3333333\n0.5862069\n0.5531915\n0.0000\n0.0416667\n0.8620690\n0.5142857\n0.8888889\n0.0000000\n1.0000000\n0.0606061\n0.3157895\n0.9444444\n0.6521739\n0.7777778\n0.7857143\n0.4210526\n0.6\n0.4285714\n0.8750\n1.0000000\n1.0000000\n1.0000000\n1.0000000\n0.4761905\n1.0000000\n0.25\n0.0000000\n0.0555556\n0.6666667\n0.4615385\n0.0277778\n0.4117647\n0.3636364\n0.6153846\n0.1666667\n0.1290323\n0.0000000\n0.6111111\n0.9750\n0.7631579\n0.5588235\n1.0000000\n0.0740741\n0.1176471\n0.7857143\n0.20\n0.3\n0.8571429\n1.0000000\n0.0833333\n0.6666667\n0.0000000\n0.00\n0.0000000\n0.0681818\n0.0000000\n0.3720930\n0.1666667\n0.9491525\n0.8809524\n0.00\n0.0634921\n0.0259740\n0.8552632\n0.2954545\n0.0000000\n0.0950608\n0.0498688\n0.3630952\n0.6043478\n0.0000000\n0.1782683\n0.4905036\n0.0432099\n1.0000000\n0.9304348\n0.6460177\n0.4269997\n1.0000000\n0.3636364\n0.0000000\n1.0000000\n0.1022364\n0.0936396\n0.7673469\n0.0000000\n0.1142433\n1.0000000\n0.3229572\n0.0289710\n0.2907489\n0.2270916\n0.0026008\n0.0200634\n\n\n2\n0.5714286\n0.2222222\n0.8461538\n0.85\n0.3333333\n0.6551724\n0.5319149\n0.2500\n0.0000000\n0.8965517\n0.5714286\n1.0000000\n0.0000000\n0.6923077\n0.0303030\n0.3157895\n0.9166667\n0.6521739\n0.3333333\n0.7142857\n0.3157895\n0.4\n0.3571429\n0.9375\n0.8333333\n0.9523810\n0.8571429\n1.0000000\n0.6666667\n0.8333333\n0.25\n0.0000000\n0.0000000\n0.6666667\n0.3076923\n0.0000000\n0.3529412\n0.1818182\n0.6923077\n0.1666667\n0.0322581\n0.0813953\n0.5000000\n1.0000\n0.7368421\n0.5294118\n0.9743590\n0.0370370\n0.2352941\n0.7857143\n0.25\n0.4\n0.8571429\n0.9444444\n0.2500000\n0.4814815\n0.0526316\n0.00\n0.0000000\n0.0000000\n0.1463415\n0.3720930\n0.1666667\n0.9322034\n0.9523810\n0.12\n0.0000000\n0.0000000\n1.0000000\n0.2954545\n0.0310078\n0.0760486\n0.0183727\n0.6428571\n0.6347826\n0.0411765\n0.1494058\n0.4519488\n0.0000000\n0.8930233\n0.9043478\n0.5840708\n0.4774129\n0.6046512\n0.4876033\n0.0733945\n0.9682243\n0.1341853\n0.1042403\n0.7265306\n0.1190325\n0.3605341\n0.9705263\n0.0856031\n0.0019980\n0.2643172\n0.2446215\n0.0269831\n0.0000000\n\n\n3\n0.2857143\n0.0000000\n0.6153846\n0.85\n0.4358974\n0.7586207\n0.5531915\n0.0000\n0.1250000\n0.8620690\n0.5714286\n1.0000000\n0.0000000\n0.4615385\n0.0303030\n0.3157895\n1.0000000\n0.7826087\n0.3333333\n0.8571429\n0.2105263\n0.3\n0.3571429\n1.0000\n0.5000000\n0.8571429\n0.8571429\n1.0000000\n1.0000000\n0.5000000\n0.25\n0.0833333\n0.3888889\n0.6666667\n0.3846154\n0.0555556\n0.2941176\n0.3636364\n0.8461538\n0.0833333\n0.0322581\n0.1744186\n0.3888889\n0.9750\n0.8421053\n0.5588235\n0.8717949\n0.0000000\n0.2941176\n0.9285714\n0.15\n0.5\n0.8928571\n0.8333333\n0.0833333\n0.5185185\n0.0526316\n0.25\n0.2972973\n0.1590909\n0.1951220\n0.3720930\n0.0000000\n0.9322034\n1.0000000\n0.00\n0.0158730\n0.0779221\n1.0000000\n0.4716970\n0.0620155\n0.0532340\n0.0000000\n0.5297619\n0.6695652\n0.0980392\n0.0899830\n0.3769810\n0.0185185\n0.8697674\n0.9478261\n0.5221239\n0.4933550\n0.5930233\n0.5206612\n0.0428135\n0.9775701\n0.0830671\n0.3144876\n0.6326531\n0.0961171\n0.6646884\n0.9747368\n0.4513619\n0.0039960\n0.3788546\n0.2135458\n0.0529909\n0.0760296\n\n\n4\n0.0000000\n0.1777778\n0.6923077\n0.70\n0.3076923\n0.6551724\n0.5531915\n0.1250\n0.0416667\n0.8620690\n0.5714286\n0.8888889\n0.0847456\n0.5384615\n0.0303030\n0.3684211\n0.9444444\n0.6521739\n0.4444444\n0.9285714\n0.1578947\n0.4\n0.4285714\n0.6875\n0.0000000\n0.8095238\n0.8571429\n1.0000000\n0.8571429\n0.5000000\n1.00\n0.0000000\n0.2777778\n0.6666667\n0.3076923\n0.0833333\n0.2941176\n0.0000000\n0.7692308\n0.1111111\n0.0645161\n0.2093023\n0.2777778\n0.9250\n0.8157895\n0.5294118\n0.7948718\n0.2222222\n0.2941176\n0.9285714\n0.20\n0.8\n0.8214286\n0.7222222\n0.0416667\n0.4814815\n0.1052632\n0.25\n0.0540541\n0.0681818\n0.1707317\n0.3953488\n0.0000000\n0.9322034\n0.8571429\n0.28\n0.0000000\n0.0779221\n0.8947368\n0.4716970\n0.1627907\n0.0570365\n0.0104987\n0.5238095\n0.6826087\n0.1313725\n0.0000000\n0.3105809\n0.0370370\n0.8558140\n0.9130435\n0.4513274\n0.4795226\n0.7209302\n0.3636364\n0.0733945\n0.8915888\n0.0000000\n0.4575972\n0.6204082\n0.0973902\n1.0000000\n0.9073684\n1.0000000\n0.0099900\n0.2745962\n0.2239044\n0.0871261\n0.1140444\n\n\n5\n0.2857143\n0.2222222\n0.4615385\n0.15\n0.3076923\n0.6206897\n0.5106383\n0.1875\n0.0000000\n0.8965517\n0.5142857\n0.8055556\n0.1271183\n0.3846154\n0.0303030\n0.3157895\n0.8888889\n0.6086957\n0.4444444\n0.7857143\n0.2631579\n0.5\n0.4285714\n0.6250\n0.3333333\n0.8571429\n0.2857143\n0.9230769\n0.7619048\n0.6666667\n0.75\n0.0000000\n0.3333333\n0.8333333\n0.3076923\n0.1388889\n0.2941176\n0.2727273\n0.7692308\n0.1388889\n0.2258065\n0.2441860\n0.3888889\n0.9250\n0.8421053\n0.3529412\n0.8461538\n0.6296296\n0.3529412\n0.9285714\n0.20\n0.8\n0.8571429\n0.9444444\n0.0000000\n0.5555556\n0.0526316\n0.50\n0.0270270\n0.1818182\n0.2195122\n0.4418605\n0.0000000\n0.9152542\n0.8809524\n0.16\n0.1111111\n0.1233766\n0.8289474\n0.4937273\n0.1782946\n0.0684438\n0.0000000\n0.4107143\n0.6304348\n0.2294118\n0.0780985\n0.2291873\n0.2253086\n0.8000000\n0.8000000\n0.4601770\n0.4841334\n0.7441860\n0.4462810\n0.1162080\n0.9065421\n0.1341853\n0.4929329\n0.6204082\n0.0795672\n0.6305638\n0.9831579\n0.8365759\n0.0139860\n0.3891336\n0.2366534\n0.2405722\n0.1636748\n\n\n6\n0.5000000\n0.2222222\n0.3076923\n0.10\n0.2051282\n0.5517241\n0.5531915\n0.1875\n0.0833333\n1.0000000\n0.5428571\n0.7777778\n0.0847456\n0.3076923\n0.0000000\n0.5263158\n0.8611111\n0.5217391\n0.2222222\n0.9285714\n0.2631579\n0.5\n0.3571429\n0.8750\n0.8333333\n0.9047619\n0.2857143\n0.8461538\n0.7619048\n0.8333333\n0.75\n0.0833333\n0.3333333\n0.8333333\n0.5384615\n0.1388889\n0.3529412\n0.3636364\n0.7692308\n0.1111111\n0.3548387\n0.2558140\n0.2777778\n0.9625\n0.8157895\n0.3529412\n0.8205128\n1.0000000\n0.3529412\n1.0000000\n0.25\n0.8\n0.9285714\n0.8333333\n0.0833333\n0.2962963\n0.0526316\n0.50\n0.0810811\n0.1590909\n0.3414634\n0.4186047\n0.1666667\n0.9152542\n0.9047619\n0.20\n0.1904762\n0.1948052\n0.8815789\n0.5157576\n0.1472868\n0.0950608\n0.0000000\n0.5892857\n0.6347826\n0.2705882\n0.0662139\n0.1135227\n0.2716049\n0.7023256\n0.4956522\n0.5221239\n0.4518578\n0.6860465\n0.3801653\n0.0856269\n0.9009346\n0.1597444\n0.4151943\n0.6612245\n0.0795672\n0.2982196\n0.9052632\n0.7548638\n0.0139860\n0.7026432\n0.2023904\n0.1911573\n0.1235480\n\n\n7\n0.7857143\n0.2222222\n0.2307692\n0.10\n0.2051282\n0.4482759\n0.6170213\n0.5625\n0.1250000\n0.9310345\n0.6571429\n0.8611111\n0.2372897\n0.5384615\n0.0909091\n0.1052632\n0.7777778\n0.4347826\n0.3333333\n1.0000000\n0.3157895\n0.5\n0.2857143\n0.8125\n0.8333333\n0.8571429\n0.1428571\n0.8461538\n0.7619048\n0.6666667\n0.25\n0.1666667\n0.5000000\n0.6666667\n0.3846154\n0.1111111\n0.4117647\n0.2727273\n0.6923077\n0.0833333\n0.4193548\n0.1976744\n0.2500000\n0.8625\n0.8157895\n0.2941176\n0.7435897\n0.8888889\n0.3529412\n0.7142857\n0.30\n0.6\n0.8928571\n0.7222222\n0.1666667\n0.1481481\n0.1578947\n0.75\n0.1081081\n0.1136364\n0.3414634\n0.4186047\n0.0833333\n0.9322034\n0.8571429\n0.12\n0.1269841\n0.1688312\n0.8815789\n0.4716970\n0.2713178\n0.0532340\n0.1338583\n0.7023810\n0.6173913\n0.3411765\n0.0509338\n0.0000000\n0.2654321\n0.6465116\n0.5739130\n0.7345133\n0.3965283\n0.6046512\n0.3884298\n0.1314985\n0.9102804\n0.2907348\n0.3639576\n0.6448980\n0.0630172\n0.0000000\n0.8357895\n0.7120623\n0.0000000\n0.6292217\n0.1856574\n0.1989597\n0.0865892\n\n\n8\n0.7857143\n0.1333333\n0.1538462\n0.05\n0.2307692\n0.3448276\n0.7659574\n0.5000\n0.0833333\n0.8275862\n0.6285714\n0.8333333\n0.3389844\n0.6923077\n0.1212121\n0.2105263\n0.7222222\n0.3478261\n0.2222222\n0.9285714\n0.3157895\n0.5\n0.3571429\n0.5625\n0.8333333\n0.8571429\n0.1428571\n1.0000000\n0.8095238\n0.5000000\n0.25\n0.1666667\n0.5000000\n0.5000000\n0.6923077\n0.1944444\n0.4705882\n0.1818182\n0.6153846\n0.1388889\n0.4193548\n0.2325581\n0.1111111\n0.7750\n0.8421053\n0.2647059\n0.7179487\n0.7037037\n0.4117647\n0.7142857\n0.25\n0.8\n0.8928571\n0.8333333\n0.1666667\n0.0000000\n0.4210526\n0.00\n0.0810811\n0.2500000\n0.3170732\n0.3953488\n0.0833333\n0.9322034\n0.7380952\n0.20\n0.1587302\n0.1883117\n0.8947368\n0.3395152\n0.4263566\n0.0646413\n0.2729659\n0.8273810\n0.5913043\n0.3980392\n0.0271647\n0.0556904\n0.2839506\n0.4697674\n0.3304348\n0.8938053\n0.3734743\n0.6860465\n0.3801653\n0.1009174\n0.9140187\n0.2683706\n0.3975265\n0.7387755\n0.0439211\n0.2685460\n0.8126316\n0.6848249\n0.0009990\n1.0000000\n0.0000000\n0.1807542\n0.1224921\n\n\n9\n0.5000000\n0.3555556\n0.0000000\n0.10\n0.2307692\n0.4827586\n0.7872340\n0.3750\n0.0833333\n0.7931034\n0.7142857\n0.7777778\n0.2372897\n0.6923077\n0.1212121\n0.2105263\n0.7500000\n0.3478261\n0.1111111\n0.7857143\n0.2631579\n0.5\n0.1428571\n0.0000\n0.8333333\n0.8095238\n0.1428571\n1.0000000\n0.7142857\n0.5000000\n0.50\n0.1666667\n0.4444444\n0.3333333\n0.6923077\n0.2222222\n0.3529412\n0.2727273\n0.3846154\n0.1944444\n0.3870968\n0.3255814\n0.0000000\n0.4125\n0.7894737\n0.2352941\n0.9230769\n0.4814815\n0.3529412\n0.6428571\n0.20\n0.6\n0.9285714\n0.7777778\n0.0833333\n0.2592593\n0.2105263\n0.00\n0.1351351\n0.2727273\n0.2682927\n0.2325581\n0.1666667\n0.8474576\n0.6190476\n0.56\n0.1428571\n0.1623377\n0.8684211\n0.2954545\n0.3798450\n0.0532340\n0.3333333\n0.9404762\n0.4304348\n0.4627451\n0.1086587\n0.1756389\n0.5308642\n0.5720930\n0.2086957\n0.9026549\n0.2720369\n0.6162791\n0.2892562\n0.1406728\n0.7607477\n0.1373802\n0.4169611\n0.6979592\n0.0235519\n0.3991098\n0.7768421\n0.5992218\n0.0119880\n0.6402349\n0.1673307\n0.1417425\n0.0844773\n\n\n10\n0.5714286\n0.3555556\n0.0769231\n0.25\n0.1025641\n0.4482759\n0.9148936\n0.0625\n0.0833333\n0.7241379\n0.7428571\n0.7777778\n0.2372897\n0.6923077\n0.1212121\n0.1052632\n0.7777778\n0.0434783\n0.1111111\n0.7857143\n0.4736842\n0.4\n0.1428571\n0.1875\n0.6666667\n0.7619048\n0.2857143\n0.8461538\n0.7142857\n0.5000000\n0.75\n0.2500000\n0.5000000\n0.5000000\n0.6153846\n0.2500000\n0.5882353\n0.3636364\n0.3846154\n0.2222222\n0.3225806\n0.3604651\n0.3888889\n0.3625\n0.7894737\n0.0882353\n0.8461538\n0.4074074\n0.3529412\n0.7857143\n0.20\n0.8\n0.8571429\n0.7777778\n0.1666667\n0.1111111\n0.2105263\n0.25\n0.1621622\n0.2500000\n0.3170732\n0.2325581\n0.0833333\n1.0000000\n0.6190476\n0.48\n0.1428571\n0.1753247\n0.9342105\n0.4496667\n0.4263566\n0.0646413\n0.3805774\n0.6904762\n0.5086957\n0.4823529\n0.0662139\n0.3105809\n0.6666667\n0.6790698\n0.1217391\n0.7433628\n0.2213181\n0.5232558\n0.2314050\n0.1253823\n0.7009346\n0.1341853\n0.5229682\n0.6897959\n0.0197327\n0.2997033\n0.8063158\n0.6459144\n0.0509491\n0.6071953\n0.1737052\n0.0845254\n0.0591341\n\n\n\n\n\n\n\n\nGrupları 4 farklı kümeye ayıracağız. Kümeleme için hiyerarşik algoritmasını; seriler arası uzaklık için Dinamik Zaman Bükme yöntemini kullanacağız.\n\n\n\nAşağıda, ilk 5 grubun kümelerini görüyorsunuz.\n\n\n\n\n\ngrup\nkume\n\n\n\n\nG1\n1\n\n\nG2\n1\n\n\nG3\n2\n\n\nG4\n2\n\n\nG5\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBu serilerin daha net bir fotoğrafını çekelim. Yani her bir grubun ortalamasını alacağız. Aşağıda da göreceğiniz üzere ortalama hareketler 4’e ayrılıyor.\n\nYükseliş sonrası düşüş\nDüşüş sonrası yükseliş\nSürekli yükseliş\nSürekli düşüş\n\n\n\n\n\n\nMarkov zinciri ile hesaplanmış kümeler arası geçiş olasılıkları aşağıdaki gibidir. Bu tablo, bir kümeden diğer bir kümeye geçiş olasılıkları vermektedir.\n\n\n\n\n\n\n\n\nX\n1\n2\n3\n4\n\n\n\n\n1\n4\n2\n7\n5\n\n\n2\n3\n1\n7\n2\n\n\n3\n6\n7\n21\n8\n\n\n4\n4\n3\n8\n10\n\n\n\n\n\n\n\n\nElimizdeki son seri G99 ve bu da 3. kümede. Bu kümeden en çok geçiş yine aynı kümeye olmuş. Bunun da olasılığı %47 olmaktadır.\nÇalışmanın başında ana seride 4991 satır vardı ve biz ilk 4950 satırı almıştık. Kalan 41 serinin 3 numaralı kümedeki gibi yükseliş trendinde olmasını bekleriz. Çünkü en yüksek olasılığı burası (3’ten 3’e) olarak hesapladık.\n\n\n\n\n\n\n\n\n\n\nKümesini varsayımsal olarak 0 atadığımız son seri ile sürekli yükseliş olarak belirlediğimiz 3 no’lu kümenin %96’lık pozitif yönlü güçlü korelasyonu dikkat çekiyor. Yani, beklediğimiz gibi %47 olasılığı alan 3-3 geçişi gerçekleşti diyebiliriz ancak her bir alt seri 50 günden oluştuğu ve son seri de henüz 41 gün olduğu için 9 işlem gününün geçmesi gerekiyor. 3-3’lük geçiş olasılığı hala en güçlü olasılık. Her ne kadar yakın olmasa da sonraki en yüksek olasılığın 3-4 geçişi olduğu da unutulmamalıdır.\nKodlara aşağıdan ulaşabilirsiniz.\n\nR\n\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(dtwclust)\nlibrary(markovchain)\nlibrary(corrplot)\n\ndf <- read_excel(\"data.xlsx\") %>%\nmutate(\n  tarih = as.Date(tarih)\n)\n\nggplot(df, aes(x = tarih, y = kapanis)) +\ngeom_line() +\ntheme_fivethirtyeight() +\ntheme(\n  plot.caption = element_text(face = \"italic\")\n) +\nlabs(\n  title = paste0(\n    \"SASA, \",\n    format(min(df$tarih),\"%d.%m.%Y\"),\"-\",\n    format(max(df$tarih),\"%d.%m.%Y\")\n  ),\n  caption = \"Kaynak: Reuters\"\n)\n\nggplot(df, aes(x = tarih, y = log(kapanis))) +\ngeom_line() +\ntheme_fivethirtyeight() +\ntheme(\n  plot.subtitle = element_text(face = \"italic\"),\n  plot.caption = element_text(face = \"italic\")\n) +\nlabs(\n  title = paste0(\n    \"SASA, \",\n    format(min(df$tarih),\"%d.%m.%Y\"),\"-\",\n    format(max(df$tarih),\"%d.%m.%Y\")\n  ),\n  subtitle = \"Fiyatların logaritması alınmıştır.\",\n  caption = \"Kaynak: Reuters\"\n)\n\nobs <- 4950\nn_sub <- 50\n\ndf %>%\nslice(1:obs) %>%\nmutate(t = seq(1,nrow(.),1)) %>%\nggplot(aes(x = t, y = log(kapanis))) +\ngeom_line() +\ngeom_vline(xintercept = seq(1,obs,n_sub), linetype = \"dashed\") +\ntheme_fivethirtyeight()\n\nsasa <- df %>%\nslice(1:obs) %>%\nmutate(t = seq(1,nrow(.),1)) %>%\n  mutate(\n    grup = paste0(\"G\",rep(1:(obs/n_sub), each = n_sub))\n  )\n\n  normalize <- function(x){\n\n  (x - min(x)) / (max(x) - min(x))\n\n}\n\nsasa_norm <- sasa %>%\nselect(kapanis,grup) %>%\ngroup_by(grup) %>%\nmutate(t = row_number()) %>%\nungroup() %>%\npivot_wider(names_from = \"grup\", values_from = \"kapanis\") %>%\nmutate_at(\n  vars(-t), function(x) normalize(x)\n)\n\nk <- 4L\n\ndata_cluster <- tsclust(\n  t(sasa_norm[,-1]),\n  type = \"h\",\n  k = k,\n  distance = \"dtw\"\n)\n\nclusters <- as.data.frame(cutree(data_cluster, k=k)) %>%\nrownames_to_column(., var = \"grup\") %>%\nrename(\"kume\"=2)\n\nsasa2 <- sasa %>%\narrange(grup) %>%\nleft_join(clusters, by = \"grup\") %>%\ngroup_by(grup) %>%\nmutate(n = row_number()) %>%\nmutate_at(\n  vars(kapanis), function(x) normalize(x)\n) %>%\nungroup()\n\nfor(i in 1:k){\n\n  g <- ggplot(sasa2 %>% filter(kume == i), aes(x = n, y = kapanis)) +\n  geom_line(data = sasa2 %>% filter(kume == i) %>% rename(grup2 = grup), aes(grup = grup2), color = \"gray\", size = 1) +\n  geom_line(color = \"dark blue\", size = 1) +\n  theme_fivethirtyeight() +\n  theme(axis.text = element_blank()) +\n  facet_wrap(~grup, scales = \"free\") +\n  labs(title = paste0(\"KÜME: \",i))\n\n  plot(g)\n\n}\n\npred <- sasa2 %>%\nselect(n,grup,kume,kapanis) %>%\ngroup_by(n,kume) %>%\nsummarise(kapanis_ortalama = mean(kapanis)) %>%\nungroup() %>%\narrange(kume)\n\nggplot(pred, aes(x = n, y = kapanis_ortalama)) +\ngeom_line(size = 1) +\nfacet_wrap(~kume) +\ntheme_fivethirtyeight()\n\nprobs <- as.data.frame(createSequenceMatrix(clusters$kume)) %>%\nrowid_to_column(\"X\")\n\ng99 <- clusters %>%\nfilter(grup == \"G99\") %>%\npull(kume)\n\nmax_prob <- probs %>%\nfilter(X == g99)\n\nmax_val <- max(unlist(max_prob))\nsum_vals <- sum(unlist(max_prob))\nnet_prob <- round(max_val / sum_vals, digits = 2) * 100\n\ndf3 <- df %>%\nmutate(t = seq(1,nrow(.),1)) %>%\nfilter(t > obs) %>%\nmutate(\n  n = row_number(),\n  kume = 0\n) %>%\nselect(n,kume,kapanis) %>%\nmutate_at(\n  vars(kapanis), function(x) normalize(x)\n)\n\npred2 <- pred %>%\nrename(\"kapanis\"=3) %>%\ngroup_by(kume) %>%\nslice(1:nrow(df3)) %>%\nmutate_at(\n  vars(kapanis), function(x) normalize(x)\n)\n\ndf3_cor <- rbind(df3,pred2)\n\nggplot() +\ngeom_line(\n  data = df3_cor %>% filter(kume == 0), aes(x = n, y = kapanis, group = kume),\n  color = \"red\",\n  size = 1\n) +\ngeom_line(\n  data = df3_cor %>% filter(kume != 0), aes(x = n, y = kapanis, group = kume),\n  color = \"gray30\"\n) +\ntheme_fivethirtyeight()\n\ndf3_cor <- rbind(df3,pred2) %>%\npivot_wider(names_from = \"kume\", values_from = \"kapanis\")\n\ncorrplot(cor(df3_cor[,-1]), method = \"number\", type = \"upper\")\n\n\n\nPython\n\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\ndf = pd.read_excel('data.xlsx')\ndf['tarih'] = pd.to_datetime(df['tarih'])\n\nfig, ax = plt.subplots()\nax.plot(df['tarih'], df['kapanis'], linewidth = 2)\nax.text(\n  x = 0.5,\n  y = 1.1,\n  ha = 'right',\n  va = 'bottom',\n  transform=ax.transAxes,\n  s = 'SASA, ' +\n  datetime.strftime(df['tarih'].min(),'%d.%m.%Y') +\n  '-' +\n  datetime.strftime(df['tarih'].max(),'%d.%m.%Y')\n)\nfig.text(\n  x = 0.75,\n  y = -0.05,\n  s = 'Kaynak: Reuters',\n  style = 'italic'\n)\n\nfig, ax = plt.subplots()\nax.plot(df['tarih'], np.log(df['kapanis']), linewidth = 2)\nax.text(\n  x = 0.5,\n  y = 1.1,\n  ha = 'right',\n  va = 'bottom',\n  transform=ax.transAxes,\n  s = 'SASA, ' +\n  datetime.strftime(df['tarih'].min(),'%d.%m.%Y') +\n  '-' +\n  datetime.strftime(df['tarih'].max(),'%d.%m.%Y')\n)\nax.text(\n  x = 0.45,\n  y = 1.03,\n  ha = 'right',\n  va = 'bottom',\n  transform=ax.transAxes,\n  s = 'Fiyatların logaritması alınmıştır.',\n  style  = 'italic',\n  fontsize = 12\n)\nfig.text(\n  x = 0.75,\n  y = -0.05,\n  s = 'Kaynak: Reuters',\n  style = 'italic'\n)\n\nobs = 4950\nn_sub = 50\n\ndf2 = df.iloc[0:obs,]\ndf2['t'] = list(range(1,obs+1,1))\n\n<string>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\nfig, ax = plt.subplots()\nax.plot(df2['t'], np.log(df2['kapanis']), linewidth = 2)\nax.vlines(\n  x = [100,1000],\n  ymin = np.log(df2['kapanis']).min(),\n  ymax = np.log(df['kapanis']).max(),\n  ls = ':',\n  lw = 2\n)"
  },
  {
    "objectID": "posts/20221127_post2/index.html",
    "href": "posts/20221127_post2/index.html",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "",
    "text": "Practicing code for the purpose of the blog\nCreate portfolio selection strategies through brainstorming\n\nThe portfolios that we will use are as follows:\n\nPicking stocks at random\nAnnualized Return-Risk ratio\nBIST100 or Borsa Istanbul 100 Index (Benchmark)\n\nBIST50 stocks will be used and the data you can access by downloading the post2.xlsx file from here is from Reuters.\n\nR\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\nbist50stocks <- read_excel(\"data.xlsx\")\nbist50stocks$DATE <- as.Date(bist50stocks$DATE)\n\nbist50stocks_20192021 <- bist50stocks %>%\nfilter(DATE < as.Date(\"2022-01-01\")) %>%\nmutate_at(\n    vars(-DATE), function(x) lag(lead(x)/x-1)\n) %>%\nna.omit()\n\nbist50stocks_2022 <- bist50stocks %>%\nfilter(DATE >= as.Date(\"2022-01-01\")) %>%\nmutate_at(\n    vars(-DATE), function(x) lag(lead(x)/x-1)\n) %>%\nna.omit()\n\n\nRandom\n\n\nset.seed(34)\n\nrnd_stocks <- sample(\n    x = names(bist50stocks_20192021)[-c(1,ncol(bist50stocks_20192021))],\n    size = 8,\n    replace = FALSE\n)\n\nsort(rnd_stocks)\n\n[1] \"BERA\"  \"BIMAS\" \"DOHOL\" \"KRDMD\" \"OTKAR\" \"SASA\"  \"TKFEN\" \"YKBNK\"\n\n\n\nAnnualized Return-Risk Ratio\n\n\nbist50stocks_20192021 %>%\nselect(-BIST100) %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\ngroup_by(Var) %>%\nsummarise(\n    \"Return\" = mean(Val) * 252,\n    \"Risk\" = sd(Val) * sqrt(252)\n) %>%\nungroup() %>%\nmutate(\n    \"Ratio\" = Return / Risk\n)\n\n# A tibble: 50 × 4\n   Var   Return  Risk Ratio\n   <chr>  <dbl> <dbl> <dbl>\n 1 AEFES  0.254 0.369 0.689\n 2 AKBNK  0.147 0.376 0.390\n 3 AKSA   0.872 0.390 2.24 \n 4 AKSEN  0.779 0.454 1.72 \n 5 ALARK  0.714 0.406 1.76 \n 6 ARCLK  0.468 0.370 1.26 \n 7 ASELS  0.266 0.384 0.694\n 8 BERA   0.742 0.670 1.11 \n 9 BIMAS  0.209 0.310 0.674\n10 DOHOL  0.457 0.392 1.17 \n# … with 40 more rows\n\nrr_stocks <- bist50stocks_20192021 %>%\nselect(-BIST100) %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\ngroup_by(Var) %>%\nsummarise(\n    \"Return\" = mean(Val) * 252,\n    \"Risk\" = sd(Val) * sqrt(252)\n) %>%\nungroup() %>%\nmutate(\n    \"Ratio\" = Return / Risk\n) %>%\narrange(desc(Ratio)) %>%\nslice(1:8) %>%\npull(Var)\n\nsort(rr_stocks)\n\n[1] \"AKSA\"  \"ALARK\" \"EREGL\" \"GUBRF\" \"HEKTS\" \"SASA\"  \"TOASO\" \"TTRAK\"\n\n\n\nWhich portfolio has the best returns?\n\n\ndf1 <- bist50stocks_2022 %>%\nselect(DATE,rnd_stocks) %>%\nmutate(\n    \"Return_Random\" = 1 + rowMeans(.[,-1])\n) %>%\nselect(DATE,Return_Random)\n\ndf2 <- bist50stocks_2022 %>%\nselect(DATE,rr_stocks) %>%\nmutate(\n    \"Return_RR_Ratio\" = 1 + rowMeans(.[,-1])\n) %>%\nselect(DATE,Return_RR_Ratio)\n\ndf3 <- bist50stocks_2022 %>%\nselect(DATE,BIST100) %>%\nrename(\"Return_Benchmark\" = 2) %>%\nmutate(\n    Return_Benchmark = 1 + Return_Benchmark\n)\n\ndf_final <- df1 %>%\nleft_join(df2, by = \"DATE\") %>%\nleft_join(df3, by = \"DATE\") %>%\nmutate(\n    \"PL_Random\" = NA,\n    \"PL_RR_Ratio\" = NA,\n    \"PL_Benchmark\" = NA\n)\n\nfor(i in 1:nrow(df_final)){\n\n    for(j in 1:3){\n\n        if(i == 1){\n            df_final[i,(j+4)] <- 100*df_final[i,(j+1)]\n        } else {\n            df_final[i,(j+4)] <- df_final[(i-1),(j+4)] * df_final[i,(j+1)]\n        }\n\n    }\n\n}\n\n\ndf_final %>%\nselect(DATE,PL_Random,PL_RR_Ratio,PL_Benchmark) %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\nggplot(aes(x = DATE, y = Val, group = Var, color = Var)) +\ngeom_line() +\ntheme_fivethirtyeight() +\ntheme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n) +\nscale_color_manual(values = c(\"red\",\"blue\",\"orange\"))\n\n\n\n\n\n\nPython\n\n\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport random\n\n\n\nbist50stocks = pd.read_excel('data.xlsx')\nbist50stocks_20192021 = bist50stocks[bist50stocks['DATE'] < dt.datetime(2022,1,1)]\nbist50stocks_20192021 = bist50stocks_20192021.apply(\n    lambda x: (x.shift(-1) / x - 1).shift(1) if x.name not in ['DATE'] else x\n)\nbist50stocks_20192021 = bist50stocks_20192021.dropna(axis=0, how='any')\n\nbist50stocks_2022 = bist50stocks[bist50stocks['DATE'] >= dt.datetime(2022,1,1)]\nbist50stocks_2022 = bist50stocks_2022.apply(\n    lambda x: (x.shift(-1) / x - 1).shift(1) if x.name not in ['DATE'] else x\n)\nbist50stocks_2022 = bist50stocks_2022.dropna(axis=0, how='any')\n\n\nRandom\n\n\n\nrandom.seed(34)\n\nrem = {'DATE', 'BIST100'}\nrnd_list = [\n    ele for ele in list(bist50stocks_20192021.columns) if ele not in rem\n]\nrnd_stocks = random.sample(rnd_list,8)\nsorted(rnd_stocks)\n\n['AKSA', 'EREGL', 'KCHOL', 'KORDS', 'KOZAL', 'SISE', 'SOKM', 'TCELL']\n\n\n\nAnnualized Return-Risk Ratio\n\n\n\nrr_stocks = bist50stocks_20192021.drop(['DATE','BIST100'], axis=1)\nrr_stocks = rr_stocks.apply(\n    lambda x: pd.Series({'Return': x.mean() * 252, 'Risk': x.std() * np.sqrt(252)})\n).transpose()\nrr_stocks['Ratio'] = rr_stocks['Return'] / rr_stocks['Risk']\nrr_stocks = sorted(list(rr_stocks.sort_values('Ratio', ascending=False).index)[:8])\nrr_stocks\n\n['AKSA', 'ALARK', 'EREGL', 'GUBRF', 'HEKTS', 'SASA', 'TOASO', 'TTRAK']\n\n\n\nWhich portfolio has the best returns?\n\n\n\ndf1 = bist50stocks_2022[\n    bist50stocks_2022.columns[\n        bist50stocks_2022.columns.isin(rnd_stocks)\n    ]\n]\ndf1['DATE'] = bist50stocks['DATE']\n\n<string>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\ndf1['Return_Random'] = 1 + df1.mean(axis=1)\n\n<string>:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n<string>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\ndf1 = df1[['DATE','Return_Random']]\n\ndf2 = bist50stocks_2022[\n    bist50stocks_2022.columns[\n        bist50stocks_2022.columns.isin(rr_stocks)\n    ]\n]\ndf2['DATE'] = bist50stocks['DATE']\n\n<string>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\ndf2['Return_RR_Ratio'] = 1 + df2.mean(axis=1)\n\n<string>:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n<string>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\ndf2 = df2[['DATE','Return_RR_Ratio']]\n\ndf3 = bist50stocks_2022[['DATE','BIST100']]\ndf3 = df3.rename(columns = {'BIST100':'Return_Benchmark'})\ndf3['Return_Benchmark'] = 1 + df3['Return_Benchmark']\n\ndf_final = pd.merge(\n    pd.merge(df1, df2, on='DATE'), df3, on='DATE'\n)\ndf_final[['PL_Random','PL_RR_Ratio','PL_Benchmark']] = np.nan"
  },
  {
    "objectID": "posts/20221127_post2/index.html#picking-stocks-at-random",
    "href": "posts/20221127_post2/index.html#picking-stocks-at-random",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "Picking stocks at random",
    "text": "Picking stocks at random\n\nset.seed(34)\n\nrnd_stocks <- sample(\n    x = names(bist50stocks)[-1],\n    size = 8,\n    replace = FALSE\n)\n\nrnd_stocks\n\n[1] \"OTKAR\" \"SASA\"  \"BIMAS\" \"DOHOL\" \"BERA\"  \"KRDMD\" \"TKFEN\" \"YKBNK\""
  },
  {
    "objectID": "posts/20221127_post2/index.html#positively-and-negatively-correlated-stocks",
    "href": "posts/20221127_post2/index.html#positively-and-negatively-correlated-stocks",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "Positively and Negatively Correlated Stocks",
    "text": "Positively and Negatively Correlated Stocks\n\ncor_stocks <- cor(bist50stocks[,-1])\ncor_stocks[lower.tri(cor_stocks)] <- NA\ncor_stocks <- cor_stocks %>%\nas.data.frame() %>%\nna.omit() %>%\nrownames_to_column(var = \"Var1\") %>%\npivot_longer(!Var1, names_to = \"Var2\", values_to = \"Correlation\") %>%\narrange(desc(Correlation)) %>%\nfilter(Var1 != Var2)\n\nhead(cor_stocks)\n\n# A tibble: 6 × 3\n  Var1  Var2  Correlation\n  <chr> <chr>       <dbl>\n1 AKBNK GARAN       0.968\n2 AKBNK ISCTR       0.957\n3 AKBNK YKBNK       0.947\n4 AKBNK THYAO       0.924\n5 AKBNK TUPRS       0.922\n6 AKBNK TAVHL       0.917\n\ntail(cor_stocks)\n\n# A tibble: 6 × 3\n  Var1  Var2  Correlation\n  <chr> <chr>       <dbl>\n1 AKBNK TTRAK       0.635\n2 AKBNK IPEKE       0.631\n3 AKBNK ISGYO       0.629\n4 AKBNK VESTL       0.598\n5 AKBNK KRDMD       0.578\n6 AKBNK BERA        0.303"
  },
  {
    "objectID": "posts/20221127_post2/index.html#random",
    "href": "posts/20221127_post2/index.html#random",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "Random",
    "text": "Random\n\nset.seed(34)\n\nrnd_stocks <- sample(\n    x = names(bist50stocks_20192021)[-c(1,ncol(bist50stocks_20192021))],\n    size = 8,\n    replace = FALSE\n)\n\nsort(rnd_stocks)\n\n[1] \"BERA\"  \"BIMAS\" \"DOHOL\" \"KRDMD\" \"OTKAR\" \"SASA\"  \"TKFEN\" \"YKBNK\""
  },
  {
    "objectID": "posts/20221127_post2/index.html#return-risk-ratio",
    "href": "posts/20221127_post2/index.html#return-risk-ratio",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "Return-Risk Ratio",
    "text": "Return-Risk Ratio\n\nrr_stocks <- bist50stocks_20192021 %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\ngroup_by(Var) %>%\nsummarise(Return = mean(Val)) %>%\nungroup()\n\nrr_stocks\n\n# A tibble: 50 × 2\n   Var     Return\n   <chr>    <dbl>\n 1 AEFES 0.00101 \n 2 AKBNK 0.000583\n 3 AKSA  0.00346 \n 4 AKSEN 0.00309 \n 5 ALARK 0.00283 \n 6 ARCLK 0.00186 \n 7 ASELS 0.00106 \n 8 BERA  0.00294 \n 9 BIMAS 0.000829\n10 DOHOL 0.00181 \n# … with 40 more rows"
  },
  {
    "objectID": "posts/20221127_post2/index.html#annualized-return-risk-ratio",
    "href": "posts/20221127_post2/index.html#annualized-return-risk-ratio",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "Annualized Return-Risk Ratio",
    "text": "Annualized Return-Risk Ratio\n\nrr_stocks <- bist50stocks_20192021 %>%\nselect(-BIST100) %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\ngroup_by(Var) %>%\nsummarise(\n    \"Return\" = mean(Val) * 252,\n    \"Risk\" = sd(Val) * sqrt(252)\n) %>%\nungroup() %>%\nmutate(\n    \"Ratio\" = Return / Risk\n) %>%\narrange(desc(Ratio)) %>%\nslice(1:8) %>%\npull(Var)\n\nsort(rr_stocks)\n\n[1] \"AKSA\"  \"ALARK\" \"EREGL\" \"GUBRF\" \"HEKTS\" \"SASA\"  \"TOASO\" \"TTRAK\""
  },
  {
    "objectID": "posts/20221127_post2/index.html#which-portfolio-has-the-best-returns",
    "href": "posts/20221127_post2/index.html#which-portfolio-has-the-best-returns",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "Which portfolio has the best returns?",
    "text": "Which portfolio has the best returns?\n\ndf1 <- bist50stocks_2022 %>%\nselect(DATE,rnd_stocks) %>%\nmutate(\n    \"Return_Random\" = 1 + rowMeans(.[,-1])\n) %>%\nselect(DATE,Return_Random)\n\ndf2 <- bist50stocks_2022 %>%\nselect(DATE,rr_stocks) %>%\nmutate(\n    \"Return_RR_Ratio\" = 1 + rowMeans(.[,-1])\n) %>%\nselect(DATE,Return_RR_Ratio)\n\ndf3 <- bist50stocks_2022 %>%\nselect(DATE,BIST100) %>%\nrename(\"Return_Benchmark\" = 2) %>%\nmutate(\n    Return_Benchmark = 1 + Return_Benchmark\n)\n\ndf_final <- df1 %>%\nleft_join(df2, by = \"DATE\") %>%\nleft_join(df3, by = \"DATE\") %>%\nmutate(\n    \"PL_Random\" = NA,\n    \"PL_RR_Ratio\" = NA,\n    \"PL_Benchmark\" = NA\n)\n\nfor(i in 1:nrow(df_final)){\n\n    for(j in 1:3){\n\n        if(i == 1){\n            df_final[i,(j+4)] <- 100*df_final[i,(j+1)]\n        } else {\n            df_final[i,(j+4)] <- df_final[(i-1),(j+4)] * df_final[i,(j+1)]\n        }\n\n    }\n\n}\n\n\ndf_final %>%\nselect(DATE,PL_Random,PL_RR_Ratio,PL_Benchmark) %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\nggplot(aes(x = DATE, y = Val, group = Var, color = Var)) +\ngeom_line() +\ntheme_fivethirtyeight() +\ntheme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n) +\nscale_color_manual(values = c(\"red\",\"blue\",\"orange\"))"
  },
  {
    "objectID": "posts/20221128_post2/index.html",
    "href": "posts/20221128_post2/index.html",
    "title": "Let’s Play a Game of Portfolio Selection",
    "section": "",
    "text": "Coding as in every post.\nCreating portfolio selection strategies through brainstorming.\n\nThe portfolios that we will use are as follows:\n\nPicking stocks at random\nAnnualized Return-Risk ratio\nBIST100 or Borsa Istanbul 100 Index (Benchmark)\n\nBIST50 stocks will be used and the data you can access by downloading the post2.xlsx file from here is from Reuters.\n\nR\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\nbist50stocks <- read_excel(\"data.xlsx\")\nbist50stocks$DATE <- as.Date(bist50stocks$DATE)\n\nbist50stocks_20192021 <- bist50stocks %>%\nfilter(DATE < as.Date(\"2022-01-01\")) %>%\nmutate_at(\n    vars(-DATE), function(x) lag(lead(x)/x-1)\n) %>%\nna.omit()\n\nbist50stocks_2022 <- bist50stocks %>%\nfilter(DATE >= as.Date(\"2022-01-01\")) %>%\nmutate_at(\n    vars(-DATE), function(x) lag(lead(x)/x-1)\n) %>%\nna.omit()\n\n\nRandom\n\n\nset.seed(34)\n\nrnd_stocks <- sample(\n    x = names(bist50stocks_20192021)[-c(1,ncol(bist50stocks_20192021))],\n    size = 8,\n    replace = FALSE\n)\n\nsort(rnd_stocks)\n\n[1] \"BERA\"  \"BIMAS\" \"DOHOL\" \"KRDMD\" \"OTKAR\" \"SASA\"  \"TKFEN\" \"YKBNK\"\n\n\n\nAnnualized Return-Risk Ratio\n\n\nrr_stocks <- bist50stocks_20192021 %>%\nselect(-BIST100) %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\ngroup_by(Var) %>%\nsummarise(\n    \"Return\" = mean(Val) * 252,\n    \"Risk\" = sd(Val) * sqrt(252)\n) %>%\nungroup() %>%\nmutate(\n    \"Ratio\" = Return / Risk\n) %>%\narrange(desc(Ratio)) %>%\nslice(1:8) %>%\npull(Var)\n\nsort(rr_stocks)\n\n[1] \"AKSA\"  \"ALARK\" \"EREGL\" \"GUBRF\" \"HEKTS\" \"SASA\"  \"TOASO\" \"TTRAK\"\n\n\n\nWhich portfolio has the best returns?\n\n\ndf1 <- bist50stocks_2022 %>%\nselect(DATE,rnd_stocks) %>%\nmutate(\n    \"Return_Random\" = 1 + rowMeans(.[,-1])\n) %>%\nselect(DATE,Return_Random)\n\ndf2 <- bist50stocks_2022 %>%\nselect(DATE,rr_stocks) %>%\nmutate(\n    \"Return_RR_Ratio\" = 1 + rowMeans(.[,-1])\n) %>%\nselect(DATE,Return_RR_Ratio)\n\ndf3 <- bist50stocks_2022 %>%\nselect(DATE,BIST100) %>%\nrename(\"Return_Benchmark\" = 2) %>%\nmutate(\n    Return_Benchmark = 1 + Return_Benchmark\n)\n\ndf_final <- df1 %>%\nleft_join(df2, by = \"DATE\") %>%\nleft_join(df3, by = \"DATE\") %>%\nmutate(\n    \"PL_Random\" = NA,\n    \"PL_RR_Ratio\" = NA,\n    \"PL_Benchmark\" = NA\n)\n\nfor(i in 1:nrow(df_final)){\n\n    for(j in 1:3){\n\n        if(i == 1){\n            df_final[i,(j+4)] <- 100*df_final[i,(j+1)]\n        } else {\n            df_final[i,(j+4)] <- df_final[(i-1),(j+4)] * df_final[i,(j+1)]\n        }\n\n    }\n\n}\n\n\ndf_final %>%\nselect(DATE,PL_Random,PL_RR_Ratio,PL_Benchmark) %>%\npivot_longer(!DATE, names_to = \"Var\", values_to = \"Val\") %>%\nggplot(aes(x = DATE, y = Val, group = Var, color = Var)) +\ngeom_line(size = 1) +\ntheme_fivethirtyeight() +\ntheme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n) +\nscale_color_manual(values = c(\"red\",\"blue\",\"orange\")) +\nscale_x_date(date_labels = \"%Y-%m\", date_breaks = \"1 month\")\n\n\n\n\n\n\nPython\n\n\nimport numpy as np\nimport pandas as pd\npd.options.mode.chained_assignment = None\nimport datetime as dt\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n\n\nbist50stocks = pd.read_excel('data.xlsx')\nbist50stocks_20192021 = bist50stocks[bist50stocks['DATE'] < dt.datetime(2022,1,1)]\nbist50stocks_20192021 = bist50stocks_20192021.apply(\n    lambda x: (x.shift(-1) / x - 1).shift(1) if x.name not in ['DATE'] else x\n)\nbist50stocks_20192021 = bist50stocks_20192021.dropna(axis=0, how='any')\n\nbist50stocks_2022 = bist50stocks[bist50stocks['DATE'] >= dt.datetime(2022,1,1)]\nbist50stocks_2022 = bist50stocks_2022.apply(\n    lambda x: (x.shift(-1) / x - 1).shift(1) if x.name not in ['DATE'] else x\n)\nbist50stocks_2022 = bist50stocks_2022.dropna(axis=0, how='any')\n\n\nRandom\n\n\n\nrandom.seed(34)\n\nrem = {'DATE', 'BIST100'}\nrnd_list = [\n    elem for elem in list(bist50stocks_20192021.columns) if elem not in rem\n]\nrnd_stocks = random.sample(rnd_list,8)\nsorted(rnd_stocks)\n\n['AKSA', 'EREGL', 'KCHOL', 'KORDS', 'KOZAL', 'SISE', 'SOKM', 'TCELL']\n\n\n\nAnnualized Return-Risk Ratio\n\n\n\nrr_stocks = bist50stocks_20192021.drop(['DATE','BIST100'], axis=1)\nrr_stocks = rr_stocks.apply(\n    lambda x: pd.Series({'Return': x.mean() * 252, 'Risk': x.std() * np.sqrt(252)})\n).transpose()\nrr_stocks['Ratio'] = rr_stocks['Return'] / rr_stocks['Risk']\nrr_stocks = sorted(list(rr_stocks.sort_values('Ratio', ascending=False).index)[:8])\nrr_stocks\n\n['AKSA', 'ALARK', 'EREGL', 'GUBRF', 'HEKTS', 'SASA', 'TOASO', 'TTRAK']\n\n\n\nWhich portfolio has the best returns?\n\n\n\ndf1 = bist50stocks_2022[\n    bist50stocks_2022.columns[\n        bist50stocks_2022.columns.isin(rnd_stocks)\n    ]\n]\ndf1['DATE'] = bist50stocks['DATE']\ndf1['Return_Random'] = 1 + df1.mean(axis=1,numeric_only=True)\ndf1 = df1[['DATE','Return_Random']]\n\ndf2 = bist50stocks_2022[\n    bist50stocks_2022.columns[\n        bist50stocks_2022.columns.isin(rr_stocks)\n    ]\n]\ndf2['DATE'] = bist50stocks['DATE']\ndf2['Return_RR_Ratio'] = 1 + df2.mean(axis=1,numeric_only=True)\ndf2 = df2[['DATE','Return_RR_Ratio']]\n\ndf3 = bist50stocks_2022[['DATE','BIST100']]\ndf3 = df3.rename(columns = {'BIST100':'Return_Benchmark'})\ndf3['Return_Benchmark'] = 1 + df3['Return_Benchmark']\n\ndf_final = pd.merge(\n    pd.merge(df1, df2, on='DATE'), df3, on='DATE'\n)\ndf_final[['PL_Random','PL_RR_Ratio','PL_Benchmark']] = np.nan\n\nfor i in range(len(df_final)):\n\n    for j in range(3):\n\n        if i == 0:\n\n            df_final.iloc[i,(j+4)] = 100 * df_final.iloc[i,(j+1)]\n\n        else:\n\n            df_final.iloc[i,(j+4)] = df_final.iloc[(i-1),(j+4)] * df_final.iloc[i,(j+1)]\n\n\n\ndf_final = pd.melt(\n    df_final,\n    id_vars = 'DATE',\n    value_vars = ['PL_Random','PL_RR_Ratio','PL_Benchmark']\n)\n\n\n\nfig, ax = plt.subplots(figsize=(12,8))\n\ng = sns.lineplot(\n    x = 'DATE',\n    y = 'value',\n    hue = 'variable',\n    data = df_final\n)\ng.legend_.set_title(None)\ng.set(xlabel=None)\ng.set(ylabel=None)\nfig.autofmt_xdate(rotation = 0)\n\nplt.show()"
  }
]